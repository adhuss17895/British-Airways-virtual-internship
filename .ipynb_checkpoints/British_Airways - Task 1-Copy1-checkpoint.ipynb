{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 20\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  The worst business class ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified |  Quite possibly the worst busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  I will never be flying with BA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  On the my trip to Mexico Ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  I upgraded at check in to C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified |  The worst business class ex...\n",
       "1  Not Verified |  Quite possibly the worst busin...\n",
       "2  Not Verified |  I will never be flying with BA...\n",
       "3  ✅ Trip Verified |  On the my trip to Mexico Ci...\n",
       "4  ✅ Trip Verified |  I upgraded at check in to C..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/ramva/OneDrive/Desktop/Adithya/Data Science/Projects/British-Airways-virtual-internship/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate.\n",
    " \n",
    "  Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ✅ Trip Verified |  The worst business class ex...\n",
       "1       Not Verified |  Quite possibly the worst busin...\n",
       "2       Not Verified |  I will never be flying with BA...\n",
       "3       ✅ Trip Verified |  On the my trip to Mexico Ci...\n",
       "4       ✅ Trip Verified |  I upgraded at check in to C...\n",
       "                              ...                        \n",
       "1995    ✅ Verified Review |  British Airways was known...\n",
       "1996    ✅ Verified Review |  London to Philadelphia. W...\n",
       "1997    ✅ Verified Review |  Dallas Ft Worth to Mumbai...\n",
       "1998    ✅ Verified Review |  Flew from LHR to AUS. Bri...\n",
       "1999    ✅ Verified Review |  London to Hong Kong in bu...\n",
       "Name: reviews, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('BA_reviews.csv')\n",
    "reviews = reviews.pop(\"reviews\")\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         The worst business class experience  Grou...\n",
       "1         Quite possibly the worst business class I...\n",
       "2         I will never be flying with BA again  Thi...\n",
       "3         On the my trip to Mexico City  I had the ...\n",
       "4         I upgraded at check in to Club Europe sea...\n",
       "5         I bought a return trip with BA  through W...\n",
       "6         Poor from start to finish  Six months aft...\n",
       "7        Communication and customer service non exi...\n",
       "8         That was supposed to be my flight but it ...\n",
       "9         Have no fear when your BA flight is opera...\n",
       "Name: reviews, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = reviews.str.replace(\"Trip Verified |\", ' ')\n",
    "reviews = reviews.str.replace(\"Verified Review |\", ' ')\n",
    "reviews = reviews.str.replace(\"Not Verified\", ' ')\n",
    "reviews = reviews.str.replace(\"✅\",' ')\n",
    "reviews = reviews.str.replace(\"|\",' ')\n",
    "reviews = reviews.str.replace(r'\\b(\\w{1,3})\\b','')\n",
    "reviews = reviews.apply(remove_punc)\n",
    "reviews.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the        16546\n",
       "to         11554\n",
       "and         9864\n",
       "a           7427\n",
       "was         7061\n",
       "i           6925\n",
       "in          4750\n",
       "of          4685\n",
       "on          4107\n",
       "flight      3828\n",
       "for         3745\n",
       "with        3092\n",
       "it          2713\n",
       "ba          2684\n",
       "that        2675\n",
       "my          2654\n",
       "is          2638\n",
       "we          2519\n",
       "not         2482\n",
       "were        2363\n",
       "they        2310\n",
       "at          2164\n",
       "but         2091\n",
       "had         2072\n",
       "this        2070\n",
       "have        1944\n",
       "as          1824\n",
       "no          1783\n",
       "from        1633\n",
       "service     1592\n",
       "london      1444\n",
       "very        1315\n",
       "me          1308\n",
       "you         1295\n",
       "be          1292\n",
       "so          1226\n",
       "an          1181\n",
       "are         1173\n",
       "food        1170\n",
       "seat        1158\n",
       "there       1078\n",
       "time        1077\n",
       "crew        1074\n",
       "british     1042\n",
       "class       1029\n",
       "airways     1028\n",
       "our         1026\n",
       "seats        961\n",
       "cabin        957\n",
       "t            950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words = pd.Series(' '.join(reviews).lower().split()).value_counts()[:50]\n",
    "freq_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
